# IMAGE TO JSON CONVERTOR

## Introduction

This project is based on the convertion of financial document like invoice into json(javascript object notation) format.

## Techniques for the process

We use OCR(optical character recognization) and NER(Named Entity Recognization)

- **OCR(optical character recognization):-** OCR is recognizing text in images, such as scanned documents and photos

- **NER(named entity recognization):-** NER is an method which is used for recognizing entities that are present in the text document

## Installation Process in linux

- For installing the libraries open the command and write the following command :- 
```
pip3 install -r required.txt
```

- Before installing the pytesseract, first install **tesseract** by using following command :-
```
sudo apt install tesseract-ocr
 
sudo apt install libtesseract-dev 
```

- Once the above installation is done, install pytessract via given command 
```
pip install pytesseract
```

- For installing the spacy,follow the link provided https://spacy.io/usage


## Directory Structure 

### Place the Files and Directories as bellow structure to avoid error

<pre>
.
├── app
│   ├── main.py
│   ├── prediction.py
|   ├── settings.py
|   ├── utils.py
│  
├── app/data
│   ├── TestData.pickle
│   ├── TrainData.pickle
│   ├── train.spacy
│   ├── test.spacy
│   
├── app/output
│   ├── model-best
│   └── model-last
├── app/static
│   ├── images
│   ├── js
│   ├── media
|
└── app/templates
    ├── index.html
    ├── predictions.html
    ├── scanner.html
    
 </pre>
 

Here i mention the folder structure which i have mentioned above 

In this part, we have created the main.py where we have included all the libraries which had been done in the ipynb file and after that we have done four points coordinates and also included the prediction.py file in it.

In settings.py where we have given the path where the all files are upload i.e app/static/media

In utils .py, we created the function in which it process the images after the doing the four point coordinates and than it prepprocess the data and save into the app/static/media folder

In app/data it contains all the training and testing data 

In app/output it contains training model which had been trained which had been uploaded 

In app/templates it contains all the html files which had been called in main.py for displaying the web application

## Division of the project

This project divided into **Four** catogaries:- 

### 1. Data Preparation 
In this part, we have done the data preparation using the **preparation.ipynb** in which the image which is converted into the data with the help of pytesseract generated  the csv format named **all_invoice.csv** .
- Once csv file  created we added one more column in that file named as tag and did mannual labeling **(for labeling we use BIO tagging format)** and then we converted into tab delimated text format named **all_invoice.*txt**.

- **BIO(Beginning Inside outsid):-** The BIO / IOB format (short for inside, outside, beginning) is a common tagging format for tagging tokens in a chunking task in computational linguistics (ex. named-entity recognition).
- The B- prefix before a tag indicates that the tag is the beginning of a chunk, and an I- prefix before a tag indicates that the tag is inside a chunk. - - The B- tag is used only when a tag is followed by a tag of the same type without O tokens between them. An O tag indicates that a token belongs to no entity / chunk.

### 2. Data preprocessing

In this part, we have done preprocessing the data using the **preprocessing.ipynb** , which converted into the pickle format named **TrainData.pickle and  TestData.pickle**  saved into the the data folder.
- Next we have converted into the spacy format named **train.spacy and test.spacy**  then saved into the data folder.
- For converting the pickle data into spacy format run the **preprocess.py** file.
- To run the file use the following command:-
```
python3 preprocess.py
```
- which will automatically convert into the spacy format.

## 3. Training Model
### How does training pipeline works
- Overview
![Screenshot from 2022-05-26 18-16-49](https://user-images.githubusercontent.com/37176796/170490739-6bceb675-770e-44bf-a371-9e4fa92b3d98.png)


- In this part, we download the **base_config.cfg** file from the following link https://spacy.io/usage/training.

- After downloading **base_config.cfg** file than convert into the **config.cfg** so that it can fill automatically all the default values.

- To convert into the **config.cfg** file  type the following command:-
```
python -m spacy init fill-config base_config.cfg config.cfg
```

- Now we will train the data by the following command:-  
```
python -m spacy train config.cfg --output ./output --paths.train ./data/train.spacy --paths.dev .data/dev.spacy
```

## 4. Prediction

In this part, we have created **prediction.py** file where we load the the model-best which had been generated by training the spacy model and which has stored into the output folder and after that we done further preprocessing and then we done the parsing using the re and after that we converted into the dictionary format and then using the json library we convert into the json format.

