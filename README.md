# IMAGE TO JSON CONVERTOR

## Introduction

This project is based on the convertion of financial document like invoice into json(javascript object notation) format.

## Techniques for the process

We use ocr(optical character recognization) and ner(named entity recognization)

OCR(optical character recognization):- OCR is recognizing text in images, such as scanned documents and photos

NER(named entity recognization):- NER is an method which is used for recognizing entities that are present in the text document

## Installation Process in linux

for installing the library just open the command and write the following command pip install -r required.txt. Before installing the pytesseract, first install the following command 1. sudo apt install tesseract-ocr 2. sudo apt install libtesseract-dev after that install pytessaract via pip command.
for installing the spacy,follow the link provided https://spacy.io/usage


## Division of the project

This project divided into four catogaries

### 1. Data Preparation 
In this part, we have done the data preparation using the preparation.ipynb in which the image which is converted into the data with the help of pytesseract and after than we have converted into the csv format (all_invoice.csv) and after that we have done created one column which we have named as tag and after that we have done mannual labeling(for labeling we use BIO tagging format) and after that we converted into tab delimated text format(all_invoice.*txt)

BIO(Beginning Inside outsid):- The BIO / IOB format (short for inside, outside, beginning) is a common tagging format for tagging tokens in a chunking task in computational linguistics (ex. named-entity recognition). The B- prefix before a tag indicates that the tag is the beginning of a chunk, and an I- prefix before a tag indicates that the tag is inside a chunk. The B- tag is used only when a tag is followed by a tag of the same type without O tokens between them. An O tag indicates that a token belongs to no entity / chunk.

### 2. Data preprocessing

In this part, we have done preprocessing the data using the preprocessing.ipynb and after that we have converted into the pickle format  (TrainData.pickle , TestData.pickle) which we have saved into the the data folder and after that we have converted into the spacy format(train.spacy , test.spacy) which we also saved into the data folder. For converting the pickle data into spacy format just run the preprocess.py file by the following command python preprocess.py which will automatically convert into the spacy format.

### 3. Training Model
#### How does training pipeline works
![Screenshot from 2022-05-26 18-16-49](https://user-images.githubusercontent.com/37176796/170490739-6bceb675-770e-44bf-a371-9e4fa92b3d98.png)


In this part, we download the base_config.cfg file from the following link https://spacy.io/usage/training

After downloading the base_config.cfg file than convert into the config.cfg so that it can fill automatically all the default values

For convert into the config.cfg file just type the following command in terminal

python -m spacy init fill-config base_config.cfg config.cfg

Now we will train the data by the following command in terminal 

python -m spacy train config.cfg --output ./output --paths.train ./data/train.spacy --paths.dev .data/dev.spacy

### 4. Prediction

In this part, we have created prediction.py file where we load the the model-best which had been generated by training the spacy model and which has stored into the output folder and after that we done further preprocessing and then we done the parsing using the re and after that we converted into the dictionary format and then using the json library we convert into the json format

## Web Application

<pre>
.
├── Resumes
│   ├── CVs/
│   ├── collectCV.py
│  
├── Model
│   ├── Model_Training.ipynb
│   ├── Extraction_from_posts.ipynb
│   ├── Sentence_Extraction.ipynb
│   ├── StackExchange/
│   ├── stackexchange_model
│   
├── Filter
│   ├── CV_ranking.ipynb
│   ├── Using Spacy Model.ipynb
│   ├── With Word2Vec.ipynb
│   ├── jd.csv
│   └── prc_data.csv
│   
└── Extract
    ├── Section_Extraction.ipynb
    ├── convertDocxToText.py
    ├── pdf2txt.py
    ├── zipextract.py
    
 </pre>
